{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parliament Topics & Chess Classifier\n",
    "\n",
    "This notebook implements two pipelines:\n",
    "\n",
    "1. **Topic Clustering** using TF-IDF and KMeans on European Parliament debates.\n",
    "2. **Classification** of chess endgames (K+R vs K) using Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import warnings, string, numpy as np, pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def basic_preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "\n",
    "# Load\n",
    "debates_df = pd.read_csv(\"debates_2022.csv\")\n",
    "debates_df = debates_df.dropna(subset=[\"talk_text\"])\n",
    "debates_df[\"clean_text\"] = debates_df[\"talk_text\"].apply(basic_preprocess)\n",
    "debates_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", min_df=5, max_df=0.9, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(debates_df[\"clean_text\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Optimal Number of Clusters (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 2\n",
    "best_score = -1\n",
    "for k in range(2, 13):\n",
    "    labels = KMeans(n_clusters=k, n_init=10, random_state=42).fit_predict(X)\n",
    "    score = silhouette_score(X, labels, sample_size=min(5000, X.shape[0]))\n",
    "    if score > best_score:\n",
    "        best_k, best_score = k, score\n",
    "print(\"Best k:\", best_k, \"with silhouette score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=best_k, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "debates_df[\"cluster\"] = labels\n",
    "\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "for i, center in enumerate(kmeans.cluster_centers_):\n",
    "    top_terms = center.argsort()[::-1][:10]\n",
    "    print(f\"Cluster {i}:\", \", \".join(terms[top_terms]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_dense = X.toarray()\n",
    "X_pca = PCA(n_components=2).fit_transform(X_dense)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels, s=5, cmap=\"tab10\")\n",
    "plt.title(\"PCA Projection of Clusters\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess Endgame Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_TO_NUM = {c: i for i, c in enumerate(\"abcdefgh\", start=1)}\n",
    "\n",
    "def letter_to_num(col):\n",
    "    return col.map(FILE_TO_NUM)\n",
    "\n",
    "def recode_targets(series):\n",
    "    mapping = {\n",
    "        \"draw\": 0,\n",
    "        **{w: 1 for w in [\"zero\", \"one\", \"two\", \"three\", \"four\"]},\n",
    "        **{w: 2 for w in [\"five\", \"six\", \"seven\", \"eight\"]},\n",
    "        **{w: 3 for w in [\"nine\", \"ten\", \"eleven\", \"twelve\"]},\n",
    "        **{w: 4 for w in [\"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\"]},\n",
    "    }\n",
    "    return series.map(mapping).astype(\"int8\")\n",
    "\n",
    "df_chess = pd.read_csv(\"king_rook_vs_king.csv\").dropna()\n",
    "for c in df_chess.columns:\n",
    "    if c.endswith(\"_file\"):\n",
    "        df_chess[c] = letter_to_num(df_chess[c])\n",
    "y = recode_targets(df_chess.pop(\"white_depth_of_win\"))\n",
    "X = df_chess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_cols = [\"white_king_file\", \"white_rook_file\", \"black_king_file\"]\n",
    "rank_cols = [\"white_king_rank\", \"white_rook_rank\", \"black_king_rank\"]\n",
    "ct = ColumnTransformer([\n",
    "    (\"files\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), file_cols),\n",
    "    (\"ranks\", \"passthrough\", rank_cols)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", ct),\n",
    "    (\"model\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(f\"CV Accuracy: {scores.mean():.3f} Â± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
